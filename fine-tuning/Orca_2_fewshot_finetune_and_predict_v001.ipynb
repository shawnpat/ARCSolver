{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e011afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -q sentencepiece\n",
    "# %pip install -q protobuf\n",
    "# %pip install -q -U bitsandbytes\n",
    "# %pip install -q -U git+https://github.com/huggingface/transformers.git\n",
    "# %pip install -q -U git+https://github.com/huggingface/peft.git\n",
    "# %pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
    "# %pip install -q scipy\n",
    "# %pip install -q -U trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_map = {\"\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f1c385",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from peft import LoraConfig, PeftModel, PeftConfig, prepare_model_for_kbit_training\n",
    "from trl import SFTTrainer\n",
    "from datasets import Dataset, concatenate_datasets\n",
    "import pandas as pd\n",
    "import re\n",
    "import ast\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "import numpy as np\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyArrayEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)\n",
    "\n",
    "\n",
    "def format_instruction_and_output(puzzle_string):\n",
    "    puzzle_dict = json.loads(puzzle_string)\n",
    "    train_pairs = puzzle_dict[\"train\"]\n",
    "    test_pairs = puzzle_dict[\"test\"]\n",
    "\n",
    "    instruction = \"\"\n",
    "    output = \"\"\n",
    "\n",
    "    for i, train_pair in enumerate(train_pairs):\n",
    "        if i > 0:\n",
    "            instruction += \" \"\n",
    "        train_input_string = str(train_pair[\"input\"])\n",
    "        train_input_string = train_input_string.replace(\" \", \"\")\n",
    "        instruction += \"Train_\" + str(i + 1) + \"_Input=\" + train_input_string\n",
    "        \n",
    "        train_output_string = str(train_pair[\"output\"])\n",
    "        train_output_string = train_output_string.replace(\" \", \"\")\n",
    "        instruction += \" Train_\" + str(i + 1) + \"_Output=\" + train_output_string\n",
    "\n",
    "    for i, test_pair in enumerate(test_pairs):\n",
    "        test_input_string = str(test_pair[\"input\"])\n",
    "        test_input_string = test_input_string.replace(\" \", \"\")\n",
    "        instruction += \" Test_\" + str(i + 1) + \"_Input=\" + test_input_string\n",
    "        \n",
    "        test_output_string = str(test_pair[\"output\"])\n",
    "        test_output_string = test_output_string.replace(\" \", \"\")\n",
    "        output += \"Test_\" + str(i + 1) + \"_Output=\" + test_output_string\n",
    "\n",
    "    return instruction, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_prompt(data_point):\n",
    "    user_message = data_point[\"instruction\"]\n",
    "    assistant_message = data_point[\"output\"]\n",
    "    text = f\"<|im_start|>user\\n{user_message}<|im_end|>\\n<|im_start|>assistant\\n{assistant_message}<|im_end|>\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    r=64,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model_name = \"microsoft/Orca-2-13b\"\n",
    "base_model_name = \"merged_models/Orca2_merged_finetune_1\"\n",
    "\n",
    "new_adapter_name = \"TEMP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"data/step_2/evaluation_max_3_trains_1_test/\"\n",
    "count = 0\n",
    "correct = 0\n",
    "too_long_count = 0\n",
    "for root, dirs, files in os.walk(root_dir):\n",
    "    for name in files:\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        if \".json\" not in name:\n",
    "            continue\n",
    "            \n",
    "        file_path = os.path.join(root, name)\n",
    "        print(\"***********************************************************************\")\n",
    "        print(file_path)\n",
    "\n",
    "        with open(file_path, \"r\") as f:\n",
    "            data = json.load(f)\n",
    "\n",
    "        train_tasks = data[\"train\"]\n",
    "        test_tasks = data[\"test\"]\n",
    "\n",
    "        if len(train_tasks) > 3:\n",
    "            train_tasks = train_tasks[:3]\n",
    "\n",
    "        for i, test_task in enumerate(test_tasks):\n",
    "            test_task = [test_task]\n",
    "\n",
    "            # token length\n",
    "            prompt = instruction + \" \" + output\n",
    "            tokenized_request = tokenizer.tokenize(prompt)\n",
    "            token_length = len(tokenized_request)\n",
    "            if token_length <= 4096:\n",
    "                ############################# TRAIN #############################\n",
    "                rot_range = 4\n",
    "                flip_range = 2\n",
    "                color_range = 9\n",
    "                \n",
    "                puzzles = []\n",
    "                \n",
    "                num_train_tasks = len(train_tasks)\n",
    "                num_test_tasks = len(test_tasks)\n",
    "\n",
    "                aug_range = num_train_tasks\n",
    "                num_augmented = rot_range * flip_range * color_range * aug_range\n",
    "\n",
    "                colors = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "                shifted_colors = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "                augmentation_count = 0\n",
    "                for rot_num in range(rot_range):\n",
    "                    for flip_num in range(flip_range):\n",
    "                        for color_num in range(color_range):\n",
    "                            for aug_num in range(aug_range):\n",
    "                                augmentation_count += 1\n",
    "\n",
    "                                task = {\n",
    "                                    \"train\": [\n",
    "                                        {\"input\": [], \"output\": []},\n",
    "                                    ],\n",
    "                                    \"test\": [{\"input\": [], \"output\": []}],\n",
    "                                }\n",
    "\n",
    "                                while len(task[\"train\"]) < num_train_tasks - 1:\n",
    "                                    task[\"train\"].append({\"input\": [], \"output\": []})\n",
    "\n",
    "                                while len(task[\"test\"]) < num_test_tasks:\n",
    "                                    task[\"test\"].append({\"input\": [], \"output\": []})\n",
    "\n",
    "                                augmented_test_tasks = [train_tasks[aug_num]]\n",
    "\n",
    "                                next_aug = aug_num + 1\n",
    "                                if next_aug > num_train_tasks - 1:\n",
    "                                    next_aug = next_aug - num_train_tasks\n",
    "\n",
    "                                augmented_train_tasks = [\n",
    "                                    train_tasks[next_aug],\n",
    "                                ]\n",
    "\n",
    "                                while len(augmented_train_tasks) < num_train_tasks - 1:\n",
    "                                    next_aug += 1\n",
    "                                    if next_aug > num_train_tasks - 1:\n",
    "                                        next_aug = next_aug - num_train_tasks\n",
    "                                    augmented_train_tasks.append(train_tasks[next_aug])\n",
    "\n",
    "                                for i, augmented_train_task in enumerate(augmented_train_tasks):\n",
    "                                    input = np.array(augmented_train_task[\"input\"])\n",
    "                                    output = np.array(augmented_train_task[\"output\"])\n",
    "\n",
    "                                    input_grid_dim_x = input.shape[0]\n",
    "                                    input_grid_dim_y = input.shape[1]\n",
    "\n",
    "                                    output_grid_dim_x = output.shape[0]\n",
    "                                    output_grid_dim_y = output.shape[1]\n",
    "\n",
    "                                    if color_num > 0:\n",
    "                                        for orig_index in range(len(colors)):\n",
    "                                            swap_index = orig_index + color_num\n",
    "                                            if swap_index >= len(colors):\n",
    "                                                swap_index = (orig_index + color_num) - len(\n",
    "                                                    colors\n",
    "                                                )\n",
    "                                            shifted_colors[orig_index] = colors[swap_index]\n",
    "                                        mapping = dict(zip(colors, shifted_colors))\n",
    "\n",
    "                                        for x in range(input_grid_dim_x):\n",
    "                                            for y in range(input_grid_dim_y):\n",
    "                                                if input[x, y] != 0:\n",
    "                                                    input[x, y] = mapping[input[x, y]]\n",
    "\n",
    "                                        for x in range(output_grid_dim_x):\n",
    "                                            for y in range(output_grid_dim_y):\n",
    "                                                if output[x, y] != 0:\n",
    "                                                    output[x, y] = mapping[output[x, y]]\n",
    "\n",
    "                                    if rot_num > 0:\n",
    "                                        input = np.rot90(input, k=rot_num).copy()\n",
    "                                        output = np.rot90(output, k=rot_num).copy()\n",
    "\n",
    "                                    if flip_num > 0:\n",
    "                                        if flip_num == 1:\n",
    "                                            input = np.flipud(input).copy()\n",
    "                                            output = np.flipud(output).copy()\n",
    "                                        else:\n",
    "                                            input = np.fliplr(input).copy()\n",
    "                                            output = np.fliplr(output).copy()\n",
    "\n",
    "                                    task[\"train\"][i][\"input\"] = input\n",
    "                                    task[\"train\"][i][\"output\"] = output\n",
    "\n",
    "                                for i, augmented_test_task in enumerate(augmented_test_tasks):\n",
    "                                    input = np.array(augmented_test_task[\"input\"])\n",
    "                                    output = np.array(augmented_test_task[\"output\"])\n",
    "\n",
    "                                    input_grid_dim_x = input.shape[0]\n",
    "                                    input_grid_dim_y = input.shape[1]\n",
    "\n",
    "                                    output_grid_dim_x = output.shape[0]\n",
    "                                    output_grid_dim_y = output.shape[1]\n",
    "\n",
    "                                    if color_num > 0:\n",
    "                                        for orig_index in range(len(colors)):\n",
    "                                            swap_index = orig_index + color_num\n",
    "                                            if swap_index >= len(colors):\n",
    "                                                swap_index = (orig_index + color_num) - len(\n",
    "                                                    colors\n",
    "                                                )\n",
    "                                            shifted_colors[orig_index] = colors[swap_index]\n",
    "                                        mapping = dict(zip(colors, shifted_colors))\n",
    "\n",
    "                                        for x in range(input_grid_dim_x):\n",
    "                                            for y in range(input_grid_dim_y):\n",
    "                                                if input[x, y] != 0:\n",
    "                                                    input[x, y] = mapping[input[x, y]]\n",
    "\n",
    "                                        for x in range(output_grid_dim_x):\n",
    "                                            for y in range(output_grid_dim_y):\n",
    "                                                if output[x, y] != 0:\n",
    "                                                    output[x, y] = mapping[output[x, y]]\n",
    "\n",
    "                                    if rot_num > 0:\n",
    "                                        input = np.rot90(input, k=rot_num).copy()\n",
    "                                        output = np.rot90(output, k=rot_num).copy()\n",
    "\n",
    "                                    if flip_num > 0:\n",
    "                                        if flip_num == 1:\n",
    "                                            input = np.flipud(input).copy()\n",
    "                                            output = np.flipud(output).copy()\n",
    "                                        else:\n",
    "                                            input = np.fliplr(input).copy()\n",
    "                                            output = np.fliplr(output).copy()\n",
    "\n",
    "                                    task[\"test\"][i][\"input\"] = input\n",
    "                                    task[\"test\"][i][\"output\"] = output\n",
    "                                    \n",
    "                                json_string = json.dumps(data, cls=NumpyArrayEncoder)\n",
    "                                instruction, output = format_instruction_and_output(json_string)\n",
    "                                \n",
    "                                puzzles.append({\"instruction\": instruction, \"output\": output})\n",
    "                                \n",
    "                json_string = json.dumps(puzzles, cls=NumpyArrayEncoder)\n",
    "                \n",
    "                df = pd.read_json(json_string)\n",
    "\n",
    "                # Convert the pandas dataframe to a dataset\n",
    "                dataset = Dataset.from_pandas(df)\n",
    "\n",
    "                # add the \"prompt\" column in the dataset\n",
    "                text_column = [generate_prompt(data_point) for data_point in dataset]\n",
    "                dataset = dataset.add_column(\"prompt\", text_column)\n",
    "\n",
    "                # Load base model\n",
    "                model = AutoModelForCausalLM.from_pretrained(\n",
    "                    base_model_name,\n",
    "                    quantization_config=bnb_config,\n",
    "                    device_map=device_map,\n",
    "                    # local_files_only=True  # Add this line if the model is stored locally\n",
    "                )\n",
    "                model.config.use_cache = False\n",
    "                # model.config.pretraining_tp = 1\n",
    "                model.gradient_checkpointing_enable()\n",
    "                model = prepare_model_for_kbit_training(model)\n",
    "\n",
    "                # Load tokenizer\n",
    "                #     tokenizer = AutoTokenizer.from_pretrained(base_model_name, add_eos_token=True, use_fast=False)\n",
    "                tokenizer = AutoTokenizer.from_pretrained(base_model_name, add_eos_token=True)\n",
    "\n",
    "                tokenizer.pad_token = tokenizer.eos_token\n",
    "                tokenizer.padding_side = \"right\"  # Fix weird overflow issue with fp16 training\n",
    "\n",
    "                per_device_train_batch_size = 1\n",
    "                gradient_accumulation_steps = 4\n",
    "                max_seq_length = 4096\n",
    "\n",
    "                output_dir = \"results/\" + new_adapter_name\n",
    "\n",
    "                steps_per_epoch = len(dataset) // (\n",
    "                    per_device_train_batch_size * gradient_accumulation_steps\n",
    "                )\n",
    "                print(\"Steps:\", steps_per_epoch)\n",
    "\n",
    "                # Set training parameters\n",
    "                training_arguments = TrainingArguments(\n",
    "                    num_train_epochs=4,\n",
    "                    output_dir=output_dir,\n",
    "                    # max_steps=steps_per_epoch,\n",
    "                    per_device_train_batch_size=per_device_train_batch_size,\n",
    "                    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "                    optim=\"paged_adamw_8bit\",\n",
    "                    lr_scheduler_type=\"cosine\",\n",
    "                    save_strategy=\"steps\",\n",
    "                    evaluation_strategy=\"no\",\n",
    "                    save_steps=1000,\n",
    "                    logging_steps=1,\n",
    "                    learning_rate=1e-4,\n",
    "                    fp16=True,\n",
    "                    warmup_steps=0.03,\n",
    "                    group_by_length=True,\n",
    "                    gradient_checkpointing=True,\n",
    "                )\n",
    "\n",
    "                # Set supervised fine-tuning parameters\n",
    "                trainer = SFTTrainer(\n",
    "                    model=model,\n",
    "                    train_dataset=dataset,\n",
    "                    peft_config=peft_config,\n",
    "                    dataset_text_field=\"prompt\",\n",
    "                    max_seq_length=max_seq_length,\n",
    "                    tokenizer=tokenizer,\n",
    "                    args=training_arguments,\n",
    "                )\n",
    "\n",
    "                # Train model\n",
    "                trainer.train()\n",
    "\n",
    "                # Save trained model\n",
    "                # adapter = \"adapters/\" + new_adapter_name\n",
    "                # trainer.model.save_pretrained(adapter)\n",
    "                \n",
    "                del model\n",
    "                gc.collect()\n",
    "                \n",
    "                fine_tuned_model = trainer.model\n",
    "                \n",
    "                ############################# PREDICT #############################\n",
    "                data = {\"train\": train_tasks, \"test\": test_tasks}\n",
    "                json_string = json.dumps(data, cls=NumpyArrayEncoder)\n",
    "                instruction, output = format_instruction_and_output(json_string)\n",
    "                user_message = instruction\n",
    "                query = f\"<|im_start|>user\\n{user_message}<|im_end|>\\n<|im_start|>assistant\"\n",
    "\n",
    "                encodeds = tokenizer(query, return_tensors=\"pt\", add_special_tokens=True)\n",
    "                model_inputs = encodeds.to(\"cuda\")\n",
    "\n",
    "                print(\"instruction\")\n",
    "                print(instruction)\n",
    "\n",
    "                print(\"output\")\n",
    "                print(output)\n",
    "                print(\"\")\n",
    "\n",
    "                fine_tuned_model.eval()\n",
    "                with torch.no_grad():\n",
    "                  generated_ids = fine_tuned_model.generate(**model_inputs)\n",
    "\n",
    "                decoded = tokenizer.batch_decode(generated_ids)\n",
    "                result = decoded[0]\n",
    "                result = result[len(query) :]\n",
    "\n",
    "                match = re.search(r\"Test_1_Output =\\[\\[.*?\\]\\]\", result)\n",
    "                if match:\n",
    "                    predicted_array_string = match.group(0).replace(\"Test_1_Output =\", \"\")\n",
    "                    predicted_array = ast.literal_eval(predicted_array_string)\n",
    "                    print(\"\\nPrediction:\")\n",
    "                    print(predicted_array)\n",
    "\n",
    "                    print(\"\\nGround Truth:\")\n",
    "                    target_match = re.search(r\"Test_1_Output=\\[\\[.*?\\]\\]\", output)\n",
    "                    target_array_string = target_match.group(0).replace(\"Test_1_Output=\", \"\")\n",
    "                    target_array = ast.literal_eval(target_array_string)\n",
    "                    print(target_array)\n",
    "\n",
    "                    are_equal = np.array_equal(predicted_array, target_array)\n",
    "                    if are_equal:\n",
    "                        print(\"ARRAYS ARE EQUAL!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
    "                        correct += 1\n",
    "                    else:\n",
    "                        print(\"ARRAYS NOT EQUAL.\")\n",
    "\n",
    "                else:\n",
    "                    print(\"\\nNo regx match. Full Result:\")\n",
    "                    print(result)\n",
    "                    print(\"\\nGround Truth:\")\n",
    "                    print(output)\n",
    "                \n",
    "                del fine_tuned_model\n",
    "                gc.collect()\n",
    "                count += 1\n",
    "            else:\n",
    "                print(\"token_length too long, skipping:\", token_length)\n",
    "                too_long_count += 1\n",
    "                break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
