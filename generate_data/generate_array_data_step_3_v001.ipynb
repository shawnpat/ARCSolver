{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from transformers import AutoTokenizer\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyArrayEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, np.ndarray):\n",
    "            return obj.tolist()\n",
    "        return json.JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_zero_rows_cols(permuted_array, sub_grid_x_dim, sub_grid_y_dim):\n",
    "    reshaped_array = permuted_array.reshape((sub_grid_x_dim, sub_grid_y_dim))\n",
    "    return np.any(np.all(reshaped_array == 0, axis=0)) or np.any(\n",
    "        np.all(reshaped_array == 0, axis=1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If num_prompts is 1, then we will print out the prompt. Otherwise, it will save a json file.\n",
    "num_prompts = 1\n",
    "min_grid_dim = 6\n",
    "max_grid_dim = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instruction:\n",
      "Given the following input/output train pairs of ARCSolver grids: Train_Input_1=[[0,0,0,0,0,0,0,0],[0,0,0,0,0,4,2,0],[0,0,0,0,0,2,3,0],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0]] and Train_Output_1=[[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,4,2,0,0,0,0],[0,0,2,3,0,0,0,0],[0,0,0,0,0,0,0,0]], Train_Input_2=[[0,0,0,0,0,0,0],[0,0,0,0,0,0,0],[0,0,0,0,9,6,1],[0,0,0,5,8,6,1],[0,0,0,3,0,0,4],[0,0,0,8,6,9,4],[0,0,0,0,0,0,0],[0,0,0,0,0,0,0]] and Train_Output_2=[[0,0,0,0,0,0,0],[0,0,0,0,0,0,0],[0,0,0,0,0,0,0],[0,0,0,0,0,0,0],[0,9,6,1,0,0,0],[5,8,6,1,0,0,0],[3,0,0,4,0,0,0],[8,6,9,4,0,0,0]], Train_Input_3=[[0,0,0,0,0,0,0,0],[0,0,0,0,1,7,1,0],[0,0,0,0,3,2,5,0],[0,0,0,0,7,6,2,0],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0]] and Train_Output_3=[[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,1,7,1,0,0,0,0],[0,3,2,5,0,0,0,0],[0,7,6,2,0,0,0,0],[0,0,0,0,0,0,0,0]]. Find the transformation from each input grid to output grid that is common to all 3 train pairs. Then apply this transformation to the following test input grid to get the test output grid: Test_Input_1=[[0,0,0,0,3,6,5,5],[0,0,0,0,8,7,6,8],[0,0,0,0,7,7,1,9],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0]].\n",
      "\n",
      "Output:\n",
      "The common transformation is that the non-zero element sub-grid in each train input grid is moved 2 units vertically and -3 units horizontally to get the corresponding train output grid. Therefore, Test_Output_1=[[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,3,6,5,5,0,0,0],[0,8,7,6,8,0,0,0],[0,7,7,1,9,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0],[0,0,0,0,0,0,0,0]].\n",
      "\n",
      "Max Token Length: 1102\n"
     ]
    }
   ],
   "source": [
    "import generate_prompts as gp\n",
    "\n",
    "json_file = []\n",
    "max_token_length = 0\n",
    "for i in range(num_prompts):\n",
    "    random_puzzle_type = randint(0, 5)\n",
    "    if random_puzzle_type == 0:\n",
    "        instruction, output, token_length = gp.create_move_obj_puzzle_prompt(min_grid_dim, max_grid_dim, tokenizer)\n",
    "    elif random_puzzle_type == 1:\n",
    "        instruction, output, token_length = gp.create_rotate_obj_puzzle_prompt(min_grid_dim, max_grid_dim, tokenizer)\n",
    "    elif random_puzzle_type == 2:\n",
    "        instruction, output, token_length = gp.create_mirrored_obj_puzzle_prompt(min_grid_dim, max_grid_dim, tokenizer)\n",
    "    elif random_puzzle_type == 3:\n",
    "        instruction, output, token_length = gp.create_scaled_obj_puzzle_prompt(min_grid_dim, max_grid_dim, tokenizer)\n",
    "    elif random_puzzle_type == 4:\n",
    "        instruction, output, token_length = gp.create_swapped_color_grids_prompt(min_grid_dim, max_grid_dim, tokenizer)\n",
    "    elif random_puzzle_type == 5:\n",
    "        instruction, output, token_length = gp.create_same_shape_grids_prompt(8, max_grid_dim, tokenizer)\n",
    "        \n",
    "    if token_length > max_token_length:\n",
    "        max_token_length = token_length\n",
    "\n",
    "    json_file.append({\"instruction\": instruction, \"output\": output})\n",
    "\n",
    "    if num_prompts == 1:\n",
    "        print(\"Instruction:\")\n",
    "        print(instruction)\n",
    "        print(\"\\nOutput:\")\n",
    "        print(output)\n",
    "\n",
    "if num_prompts > 1:\n",
    "    json_string = json.dumps(json_file, cls=NumpyArrayEncoder)\n",
    "    base_file_name = \"../data/ARCSolver_core_puzzles_\" + str(num_prompts)\n",
    "    filename = base_file_name + \".json\"\n",
    "    filepath = filename\n",
    "    with open(filepath, \"w\") as outfile:\n",
    "        outfile.write(json_string)\n",
    "\n",
    "print(f\"\\nMax Token Length: {max_token_length}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
