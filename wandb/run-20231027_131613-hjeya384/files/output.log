Steps per epoch: 80
Total steps: 320
/home/shawn/Projects/LLM_ARC_Solver/.venv/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:214: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.
  warnings.warn(
You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
{'loss': 0.8067, 'learning_rate': 0.000150014063818483, 'epoch': 1.0}
{'eval_loss': 0.7089760899543762, 'eval_runtime': 11.0986, 'eval_samples_per_second': 1.802, 'eval_steps_per_second': 0.27, 'epoch': 1.0}
{'loss': 0.6073, 'learning_rate': 0.00010000937587898864, 'epoch': 2.0}
{'eval_loss': 0.6535564064979553, 'eval_runtime': 11.9751, 'eval_samples_per_second': 1.67, 'eval_steps_per_second': 0.251, 'epoch': 2.0}
{'loss': 0.593, 'learning_rate': 5.000468793949432e-05, 'epoch': 3.0}
{'eval_loss': 0.6325817108154297, 'eval_runtime': 12.1982, 'eval_samples_per_second': 1.64, 'eval_steps_per_second': 0.246, 'epoch': 3.0}
{'loss': 0.5691, 'learning_rate': 0.0, 'epoch': 4.0}
{'eval_loss': 0.6294487118721008, 'eval_runtime': 12.4433, 'eval_samples_per_second': 1.607, 'eval_steps_per_second': 0.241, 'epoch': 4.0}
