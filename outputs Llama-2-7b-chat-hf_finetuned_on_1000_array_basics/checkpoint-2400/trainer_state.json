{
  "best_metric": 0.2905608117580414,
  "best_model_checkpoint": "outputs Llama-2-7b-chat-hf_finetuned_on_1000_array_basics/checkpoint-2400",
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 2400,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 1.0,
      "learning_rate": 0.00015000140626318374,
      "loss": 0.324,
      "step": 800
    },
    {
      "epoch": 1.0,
      "eval_loss": 0.29655951261520386,
      "eval_runtime": 145.4062,
      "eval_samples_per_second": 1.375,
      "eval_steps_per_second": 0.172,
      "step": 800
    },
    {
      "epoch": 2.0,
      "learning_rate": 0.00010000093750878917,
      "loss": 0.2864,
      "step": 1600
    },
    {
      "epoch": 2.0,
      "eval_loss": 0.29235193133354187,
      "eval_runtime": 147.1034,
      "eval_samples_per_second": 1.36,
      "eval_steps_per_second": 0.17,
      "step": 1600
    },
    {
      "epoch": 3.0,
      "learning_rate": 5.000046875439458e-05,
      "loss": 0.2835,
      "step": 2400
    },
    {
      "epoch": 3.0,
      "eval_loss": 0.2905608117580414,
      "eval_runtime": 153.2881,
      "eval_samples_per_second": 1.305,
      "eval_steps_per_second": 0.163,
      "step": 2400
    }
  ],
  "logging_steps": 800,
  "max_steps": 3200,
  "num_train_epochs": 4,
  "save_steps": 800,
  "total_flos": 1.814279881059533e+16,
  "trial_name": null,
  "trial_params": null
}
